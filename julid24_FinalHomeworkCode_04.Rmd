---
title: "julid24_OriginalHomeworkCode_04"
author: "Julianna D."
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: cerulean 
    toc: yes
    toc_float: true
---
# Problem 1 - Z-test function
Write a simple R function, Z.prop.test(), that can perform one or two sample Z-tests for proportion data using the following guidelines:  
-- p1 and n1 (no default) representing the estimated proportion and sample size  
-- p2 and n2 (both defaulting to NULL) that contain a second sample's proportion and sample size data in the even of a two-sample test  
-- pO (no default) as the expected value for the population proportion  
-- alternative default "two.sided" and conf.level (default 0.95) used in the same way as in t.test()  
-- A two-sample test: p1 is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”  
-- The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.  
-- The function should contain a check for the rules of thumb we have talked about (n∗p>5
 and n∗(1−p)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.  
-- The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.  

```{r}
Z.prop.test <- function(p1, n1, p2 = NULL, n2 = NULL, p0, alternative = "two.sided", conf.level = 0.95) {

# Enter estimated proportion, sample size, and expected value for population proportion
  if (missing(p1) || missing(n1) || missing(p0)) {
    stop("You must provide values for p1, n1, and p0.")
  }
  
# Rules of thumb
  if (n1 * p1 < 5 || n1 * (1 - p1) < 5) {
    warning("The rules of thumb (n*p > 5 and n*(1-p) > 5) may not be satisfied for the first sample.")
  }
  
  if (!is.null(p2) && !is.null(n2)) {
    if (n2 * p2 < 5 || n2 * (1 - p2) < 5) {
      warning("The rules of thumb (n*p > 5 and n*(1-p) > 5) may not be satisfied for the second sample.")
    }
  }
  
# For proportions, we calculate point estimates using the p-hat formula
  phat1 <- p1
  se1 <- sqrt(p1 * (1 - p1) / n1)
  
  if (!is.null(p2) && !is.null(n2)) {
    phat2 <- p2
    se2 <- sqrt(p2 * (1 - p2) / n2)
    se_diff <- sqrt(se1^2 / n1 + se2^2 / n2)
  }
  
# Test statistic
  if (is.null(p2) || is.null(n2)) {
    z <- (phat1 - p0) / se1
  } else {
    z <- (phat1 - phat2) / se_diff
  }
  
# Calculate p-value 
  if (alternative == "two.sided") {
    pval <- 2 * pnorm(abs(z), lower.tail = FALSE)
  } else if (alternative == "greater") {
    pval <- 1 - pnorm(z)
  } else if (alternative == "less") {
    pval <- pnorm(z)
  } else {
    stop("Invalid alternative hypothesis. Use 'two.sided', 'less', or 'greater'.")
  }
  
# Find Confidence Interval
  alpha <- 1 - conf.level
  z_crit <- qnorm(1 - alpha / 2)
  marg_error <- z_crit * se_diff
  
  if (is.null(p2) || is.null(n2)) {
    ci_lower <- p1 - marg_error
    ci_upper <- p1 + marg_error
  } else {
    ci_lower <- (p1 - p2) - marg_error
    ci_upper <- (p1 - p2) + marg_error
  }
  
# Results List
  result <- list(
    Z = z,
    P = pval,
    CI = c(ci_lower, ci_upper),
    method = "Z-test for Proportions",
    alternative = alternative
  )
  
  return(result)
}
```

# Problem 2 - Kalimar & Cooper Dataset

Using MaxLongevity_m and Brain_Size_Species_Mean, do the following for longevity~brain size and log(longevity)~log(brain size):  
-- Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).

-- Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.

-- Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

-- Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

```{r}
library(curl)
HWdata <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/KamilarAndCooperData.csv")
kc <- read.csv(HWdata, header = TRUE, stringsAsFactors = FALSE)
attach(kc)
```


## Longevity~Brain Size

### Fit the Model

1. Fit the regression model and produce a {ggplot2} scatterplot with the fitted line superimposed upon the data. Append the fitted model equation to your plot (HINT: use geom_text().
```{r}
# Referenced Module 12
# Fitting the model for longevity~brain size
lb_model <- lm(MaxLongevity_m~Brain_Size_Species_Mean, data=kc)
print(lb_model)

# Referenced: https://ggplot2.tidyverse.org/reference/geom_text.html 
library(ggplot2)

# Scatterplot of fitted model for longevity~brain size w/ fitted line 
scatter_plot <- ggplot(kc, aes(Brain_Size_Species_Mean, MaxLongevity_m)) +
  geom_point() +
  geom_smooth(method = "lm", formula=y~x, color = "purple") +  
  geom_text(aes(label = paste("y =", round(coef(lb_model)[Brain_Size_Species_Mean], 3), "x +", round(coef(lb_model)[MaxLongevity_m], 3))),
            x = min(kc$Brain_Size_Species_Mean) + 1, y = max(kc$MaxLongevity_m) - 1, hjust = 0, vjust = 1, size = 5) +
  labs(title = "longevity~brain size Scatterplot w/ Fitted Line",
       x = "Brain_Size_Species_Mean",
       y = "MaxLongevity_m") + geom_text(aes(x=100, y=750, label=("y = 248.95 + 1.2180")), size=4, color="purple")

print(scatter_plot)
```


### Slope Estimate (beta 1)

2. ID and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypothesis H-: β1=0; HA: β1≠0.
```{r}
# Longevity~Brain Size
summary(lb_model)
```

Interpretation - Based on the summary, the point estimate of the slope (β1) is 1.2180. This does not match our hypothesis H-: β1=0, and therefore satisfies our alternative hypothesis, HA: β1≠0. The outcome is that we reject the null hypothesis.

### Confidence and Prediction Interval

-- Also find a 90% confidence interval for the slope (β1) parameter (question driectly from Original HW question in the Assignment).
```{r}
# Longevity~Brain Size
ci <- confint(lb_model, level=0.90)
ci
```

-- Also find a 90% prediction interval for the slope (β1) parameter (Prof. Schmitt asked for 90% PI during office hours on 10/30/23).
```{r}
# Longevity~Brain Size
pi <- predict(lb_model, level=0.90)
head(pi)
```

### Add CI and PI lines to Plot

-- add lines for the 90% confidence and prediction interval bands on the plot & add a legend. 

(I can't figure out how to add the PI bands or a legend)

```{r}
# Longevity~Brain Size
scatter_plot <- ggplot(kc, aes(Brain_Size_Species_Mean, MaxLongevity_m)) +
  geom_point() +
  geom_smooth(method = "lm", formula=y~x, color = "purple") +  
  geom_text(aes(label = paste("y =", round(coef(lb_model)[Brain_Size_Species_Mean], 3), "x +", round(coef(lb_model)[MaxLongevity_m], 3))),
            x = min(kc$Brain_Size_Species_Mean) + 1, y = max(kc$MaxLongevity_m) - 1, hjust = 0, vjust = 1, size = 5) +
  labs(title = "longevity~brain size Scatterplot w/ Fitted Line",
       x = "Brain_Size_Species_Mean",
       y = "MaxLongevity_m") + geom_text(aes(x=100, y=750, label=("y = 248.95 + 1.2180")), size=4, color="purple") + geom_abline(intercept=230.54, slope=1.04, color="red") + geom_abline(intercept=267.36, slope=1.40, color="red")

print(scatter_plot)
```

### Pt. Est. 800gm Brain Wt

-- Produce a point estimate and associated 90% PI for the longevity of species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
```{r}
# Longevity~Brain Size
pi_1 <- predict(lb_model, newdata=data.frame(Brain_Size_Species_Mean=800), interval="predict", level=0.90)
print(pi_1)
```
I do not trust this model to predict observations for this value because the data does not follow a normal distribution, skewing the estimation.


## log(Longevity)~log(Brain Size)

### Fit the Model
```{r}
#Fitting the model for log(longevity)~log(brain size)
log_lb_model <- lm(log(MaxLongevity_m)~log(Brain_Size_Species_Mean), data=kc)
print(log_lb_model)

# Scatterplot of fitted model for log(longevity)~log(brain size) w/ fitted line 
scatter_plot2 <- ggplot(kc, aes(log(Brain_Size_Species_Mean), log(MaxLongevity_m))) +
  geom_point() +
  geom_smooth(method = "lm", formula = y~x, color = "orange") +
  geom_text(aes(label = paste("y =", round(coef(log_lb_model)[Brain_Size_Species_Mean], 3), "x +", round(coef(log_lb_model)[MaxLongevity_m], 3))),
            x = min(kc$Brain_Size_Species_Mean) + 1, y = max(kc$MaxLongevity_m) - 1, hjust = 0, vjust = 1, size = 5) +
  labs(title = "log(longevity)~log(brain size) Scatterplot w/ Fitted Line",
       x = "log(Brain_Size_Species_Mean)",
       y = "log(MaxLongevity_m)") + geom_text(aes(x=1.5, y=6, label=("y = 4.88 + 0.23")), size=4, color="orange")

print(scatter_plot2)
```

2. ID and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypothesis H-: β1=0; HA: β1≠0.

### Slope Estimate (beta 1)
```{r}
# log(Longevity)~log(Brain Size)
summary(log_lb_model)
```

Interpretation - Based on the summary, the point estimate for the slope (β1) is 0.23415.This does not match our hypotehsis H-: β1=0, and therefore satisfies our alternative hypothesis, HA: β1≠0. The outcome is that we reject the null hypothesis.


### Confidence and Prediction Interval

-- Also find a 90% confidence interval for the slope (β1) parameter (question driectly from Original HW question in the Assignment).
```{r}
# log(Longevity)~log(Brain Size)
ci2 <- confint(log_lb_model, level=0.90)
ci2
```

-- Also find a 90% prediction interval for the slope (β1) parameter (Prof. Schmitt asked for 90% PI during office hours on 10/30/23).
```{r}
# log(Longevity)~log(Brain Size)
pi2 <- predict(log_lb_model, level=0.90)
head(pi2)
```

### Add CI and PI lines to Plot
-- add lines for the 90% confidence and prediction interval bands on the plot & add a legend. 

(I can't figure out how to add the PI bands or a legend)

```{r}
# log(longevity)~log(brain size)
scatter_plot2 <- ggplot(kc, aes(log(Brain_Size_Species_Mean), log(MaxLongevity_m))) +
  geom_point() +
  geom_smooth(method = "lm", formula = y~x, color = "orange") +
  geom_text(aes(label = paste("y =", round(coef(log_lb_model)[Brain_Size_Species_Mean], 3), "x +", round(coef(log_lb_model)[MaxLongevity_m], 3))),
            x = min(kc$Brain_Size_Species_Mean) + 1, y = max(kc$MaxLongevity_m) - 1, hjust = 0, vjust = 1, size = 5) +
  labs(title = "log(longevity)~log(brain size) Scatterplot w/ Fitted Line",
       x = "log(Brain_Size_Species_Mean)",
       y = "log(MaxLongevity_m)") + geom_text(aes(x=1.5, y=6, label=("y = 4.88 + 0.23")), size=4, color="orange") + geom_abline(intercept=4.76, slope=0.20, color="blue") + geom_abline(intercept=4.99, slope=0.26, color="blue")

print(scatter_plot2)
```

### Pt. Est. 800gm Brain Wt

-- Produce a point estimate and associated 90% PI for the longevity of species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

```{r}
pi_2 <- predict(log_lb_model, newdata=data.frame(Brain_Size_Species_Mean=800), interval="predict", level=0.90)
print(pi_2)
```
I do trust this model to predict observations for this value because it has a more normal distribution and therefore can better estimation. 

## Comparing the 2 models

Looking at your 2 models, which do you think is better? Why?

I think the log model is better because it takes skewed data and reshapes it into a more normal distribution, reducing the range of the data and more centrality. Using this model helps give better predictions and estimates for theoretical values, such as estimating the longevity of a species with a theoretical 800gm brain weight.


# HW 4 Challenges
1) Overall, the week that this homework was due was the busiest week for me with other midterms, thus my finishing my original homework code past the "due date." I did message my peer commentary group (Angelique and Emily) on Slack earlier in the week to give them a heads up that I was very swamped with work but would get my code to them by the weekend. They replied that they were also pretty busy and would also get their original codes done by then, too. So it worked out. 
2.) Given that I was so swamped that week with midterms at the beginning of the week, by the time I started the original HW code Wednesday, I was burnt out so it took me a long time to get back in the groove and fully grasp my head around these new concepts of regression. So I particularly struggled with this homework, although Prof. did say it was going to be challenging anyways.
3.) I struggled with the first problem creating my Z.prop.test function. At first I made it using the regular Z equation, and then I realized mine was wrong when I was doing peer commentary. I overlooked the fact that it was asking to compute tests using PROPORTIONS, which requires the p-hat equation. Then I had to go back and restart, referencing the modules and reading in our textbooks. I had a hard time with the "if-else" stuff.
4.) I couldn't figure out how to add the prediction interval bars to the plot. I Googled and tested things, but it just gave me a line, not bars. Therefore, those are missing from my scatter plots. 

Although I struggled with this homework and it's not perfect, I actually did learn a lot from it and now have a stronger understanding of the use of regression models and the regression equation, etc. 